{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stanfordnlp.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RWcJM-H9hJwC",
        "CANOWCjxhHqB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC4j5zK1gBAG"
      },
      "source": [
        "Follow [Get Started](https://stanfordnlp.github.io/stanfordnlp/#get-started)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWcJM-H9hJwC"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-fJDrWIfyFe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "collapsed": true,
        "outputId": "a6409f88-52a7-4b8f-b003-e5a1ee9a7b30"
      },
      "source": [
        "!pip install stanfordnlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanfordnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/bf/5d2898febb6e993fcccd90484cba3c46353658511a41430012e901824e94/stanfordnlp-0.2.0-py3-none-any.whl (158kB)\n",
            "\r\u001b[K     |██                              | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (3.10.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.17.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (45.2.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2019.11.28)\n",
            "Installing collected packages: stanfordnlp\n",
            "Successfully installed stanfordnlp-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mMREFGMf1qq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "collapsed": true,
        "outputId": "ccdb06cb-230f-4287-d58c-e7d7b9a4adf5"
      },
      "source": [
        "import stanfordnlp\n",
        "stanfordnlp.download('en')  # Answer Y and Enter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the default treebank \"en_ewt\" for language \"en\".\n",
            "Would you like to download the models for: en_ewt now? (Y/n)\n",
            "Y\n",
            "\n",
            "Default download directory: /root/stanfordnlp_resources\n",
            "Hit enter to continue or type an alternate directory.\n",
            "\n",
            "\n",
            "Downloading models for: en_ewt\n",
            "Download location: /root/stanfordnlp_resources/en_ewt_models.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 235M/235M [00:06<00:00, 33.2MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Download complete.  Models saved to: /root/stanfordnlp_resources/en_ewt_models.zip\n",
            "Extracting models file for: en_ewt\n",
            "Cleaning up...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CANOWCjxhHqB"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joNwWZongU60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "collapsed": true,
        "outputId": "d0f1f18a-c75f-4915-abdf-2e04b210c98d"
      },
      "source": [
        "nlp = stanfordnlp.Pipeline()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: pos\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: lemma\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Building an attentional Seq2Seq model...\n",
            "Using a Bi-LSTM encoder\n",
            "Using soft attention for LSTM.\n",
            "Finetune all embeddings.\n",
            "[Running seq2seq lemmatizer with edit classifier]\n",
            "---\n",
            "Loading: depparse\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN01zcTIghSh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "063a79d3-7162-44fc-f62b-80ee0668273c"
      },
      "source": [
        "doc = nlp(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1et65UlKguNh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "6a62f3ed-e0e9-4b30-f218-b9fa6000e831"
      },
      "source": [
        "doc.sentences[0].print_dependencies()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Barack', '4', 'nsubj:pass')\n",
            "('Obama', '1', 'flat')\n",
            "('was', '4', 'aux:pass')\n",
            "('born', '0', 'root')\n",
            "('in', '6', 'case')\n",
            "('Hawaii', '4', 'obl')\n",
            "('.', '4', 'punct')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdTYNLYyhMXa"
      },
      "source": [
        "## Lemmatize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFI0SNJ8hPFI"
      },
      "source": [
        "Follow [LemmaProcessor](https://stanfordnlp.github.io/stanfordnlp/lemma.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwAkAaHTgwZM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "collapsed": true,
        "outputId": "8cfa6891-6434-44d9-e4a8-c83073efda51"
      },
      "source": [
        "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos,lemma')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: pos\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: lemma\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Building an attentional Seq2Seq model...\n",
            "Using a Bi-LSTM encoder\n",
            "Using soft attention for LSTM.\n",
            "Finetune all embeddings.\n",
            "[Running seq2seq lemmatizer with edit classifier]\n",
            "Done loading processors!\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNTfyKd0hU_T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7b2f9038-707e-45a7-d92f-2057c59b0f85"
      },
      "source": [
        "doc = nlp(\"Barack Obama was born in Hawaii.\")\n",
        "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: Barack \tlemma: Barack\n",
            "word: Obama \tlemma: Obama\n",
            "word: was \tlemma: be\n",
            "word: born \tlemma: bear\n",
            "word: in \tlemma: in\n",
            "word: Hawaii \tlemma: Hawaii\n",
            "word: . \tlemma: .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}